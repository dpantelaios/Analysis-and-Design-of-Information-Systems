[agent]
  interval = "1s"
  flush_interval = "1s"

# [[inputs.cpu]]
#   percpu = false
#   totalcpu = true

[[outputs.http]]
  url = "http://grafana-server2:3000/api/live/push/custom_stream_id"
  data_format = "influx"
  [outputs.http.headers]
  Authorization = "Bearer eyJrIjoiM2dNOTdCR3JRMDYzOFZnblFkZThoeWVpT2JNeEp6UXoiLCJuIjoiQVBJLWtleSIsImlkIjoxfQ=="
    #Authorization = "Bearer eyJrIjoiWGlhSEhYQTFuUVhrSlNyY2FickNCZGxmUHljbE9ibWIiLCJuIjoiYXBpLWtleSIsImlkIjoxfQ=="

# [[outputs.websocket]]
#   url = "wss://grafana-server2:3000/api/live/push/custom_stream_id"
#   data_format = "influx"
#   [outputs.websocket.headers]
#     Authorization = "Bearer eyJrIjoieXhXU3RBM1RHY0dBY0ZEMzFHYjlGcUc5c3JwNW9TUkEiLCJuIjoiYXBpLWtleSIsImlkIjoxfQ=="

[[outputs.influxdb]]
  urls = ["http://influxdb:8086"]
  database = "influx"
  timeout = "15s"
  username = "telegraf"
  password = "metricsmetricsmetricsmetrics"
  data_format = "influx"


[[outputs.file]]
  ## Files to write to, "stdout" is a specially handled file.
  files = ["stdout", "/tmp/metrics.out"]
  data_format = "json"
  influx_max_line_bytes = 0
  influx_sort_fields = false
  influx_uint_support = false


[[inputs.kafka_consumer]]
  # name_override = "th1_RAW"
  brokers = ["kafka:29090"]
  topics = ['raw']
  # consumer_group = "test-1"
  max_message_len = 10000000
  # data_format = "influx"
  data_format = "json"
  # data_type = "string"
  # tags = ["value"]
  # name_prefix = "bla"
  # name_suffix = "bla"
  json_time_key = "produceDate"
  json_time_format = "unix_ms"
  # json_string_fields  = ['key']
  tag_keys = ['sensorName']
  # tagpass = {sensor = ["th1"]}
  json_name_key = "sensorName"

[[inputs.kafka_consumer]]
  brokers = ["kafka:29090"]
  topics = ['aggDay15min']
  max_message_len = 1000000
  data_format = "json"
  json_time_key = "aggregationDate"
  json_time_format = "unix_ms"
  tag_keys = ['sensorName']
  json_name_key = "sensorName"
  name_prefix = "aggDay15min_"

[[inputs.kafka_consumer]]
  brokers = ["kafka:29090"]
  topics = ['aggDayDaily']
  max_message_len = 1000000
  data_format = "json"
  json_time_key = "maxDate"
  json_time_format = "unix_ms"
  tag_keys = ['sensorName']
  json_name_key = "sensorName"
  name_prefix = "aggDayDaily_"
  
[[inputs.kafka_consumer]]
  brokers = ["kafka:29090"]
  topics = ['aggDayDiff']
  max_message_len = 1000000
  data_format = "json"
  json_time_key = "diffDate"
  json_time_format = "unix_ms"
  tag_keys = ['sensorName']
  json_name_key = "sensorName"
  name_prefix = "aggDayDiff_"

[[inputs.kafka_consumer]]
  brokers = ["kafka:29090"]
  topics = ['leaks']
  max_message_len = 1000000
  data_format = "json"
  json_time_key = "leakDate"
  json_time_format = "unix_ms"
  tag_keys = ['leakType']
  json_name_key = "leakType"
  name_suffix = "_leak"

[[inputs.kafka_consumer]]
  name_override = "Total_moves"
  brokers = ["kafka:29090"]
  topics = ['totalMovements']
  max_message_len = 1000000
  data_format = "json"
  json_time_key = "totalMovesDate"
  json_time_format = "unix_ms"

[[inputs.kafka_consumer]]
  name_override = "Late_rejected"
  brokers = ["kafka:29090"]
  topics = ['lateRejected']
  max_message_len = 1000000
  data_format = "json"
  json_time_key = "produceDate"
  json_time_format = "unix_ms"
  tag_keys = ['sensorName']



